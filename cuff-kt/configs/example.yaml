dataset_path: "./dataset"

checkpoint_dir: .ckpts
seed: 12405
method: 'none'
control: 'none'
ratio: 0
exp: 'inter'
convert: False


diskt_config:
  embedding_size: 32
  num_blocks: 2
  kq_same: True
  num_attn_heads: 8
  final_fc_dim: 512
  final_fc_dim2: 256
  d_ff: 1024
  l2: 1e-5
  dropout: 0.05
  separate_qr: False

dkvmn_config:
  dim_s: 64
  size_m: 64
  dropout: 0.05

stablekt_config:
  embedding_size: 32
  num_blocks: 4
  kq_same: True
  num_attn_heads: 8
  final_fc_dim: 512
  final_fc_dim2: 256
  d_ff: 1024
  l2: 1e-5
  dropout: 0.05
  separate_qr: False
  r: 0.5
  gamma: 0.7
  num_buckets: 32
  max_distance: 100



dimkt_config:
  embedding_size: 32
  dropout: 0.1
  batch_size: 512
  difficult_levels: 100 # fixed

atdkt_config:
  embedding_size: 32
  dropout: 0.1
  num_layers: 1
  num_attn_heads: 8
  l1: 0.5
  l2: 0.5
  l3: 0.5
  start: 50


dkt_config:
  embedding_size: 32
  dropout: 0.1
  
train_config:
  wl: 0.0
  log_wandb_fold: True
  sequence_option: "recent" # early or recent
  seq_len: 100
  batch_size: 512
  eval_batch_size: 512
  num_epochs: 300
  print_epochs: 1
  max_grad_norm: 2.0
  learning_rate: 0.001
  optimizer: adam
  
  loss: BCE

  ## Model Save
  save_model: False
  save_epochs: 1
  save_model_name: "tmp"
  log_path: "logs"
